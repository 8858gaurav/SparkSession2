# Key Roles of checkpointLocation
# 1. Fault Tolerance & Recovery: f your Spark application fails (due to a cluster crash, JVM error, or network issue), Spark uses the data in the checkpoint directory to resume processing.
# 2. Maintain State Information for stateful transformations: For stateful queries (like window(), groupBy(), or dropDuplicates()), Spark must remember intermediate results (e.g., a running count). It saves this "state" into the checkpoint location so that if the job restarts, the running totals aren't lost.
# 3. Exactly-once semantics for output sinks that support it.

- Complete Mode : All the changes made due to the addition of a new
file along the previous results will be reflected in the output. The entire
updated result table will be written to the external storage.
  
- Update Mode : UPSERT(Update+Insert) Only the updates and inserts
made as per the new file added will reflect in the output. Only the rows
that are updated or newly inserted will be written to the external
storage.
  
- Append Mode : Append mode doesn’t work on Aggregation operations.
Only the new records added will be shown.

1. Complete mode - It states that the records are maintained right from the
beginning. With this feature of complete mode, it will not allow the
state-store clean activity. Therefore, Complete mode is not the right
choice to be used with Watermark.
2. Append mode - updates are not possible in append mode. Ideally, this
mode doesn’t support aggregations. However, if the watermark
boundary is set to a certain limit and there are no changes made after
this point, then the Append mode allows windowing aggregations.
The window information will be displayed only when the particular
widow expires. The limitation is that we need to wait for the watermark
boundary duration to view the window information.
3. Update mode - is mostly used along with the watermark feature
